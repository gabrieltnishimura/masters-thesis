\chapter[Related Work]{Related Work}
\label{chap:related-work}

In this section, we discuss how the literature has approached speech corpora creation, as well as the various conditions and variables considered in the process. Speech Corpus crafting itself is well established in the literature by TIMIT \cite{Lamel1992timmit} and SWITCHBOARD \cite{godfrey1992switchboard}. TIMIT creates a dataset of 6300 utterances by 630 speakers from different regions of the United States. The sentences were crafted to fit in one of the three categories: 1) dialect "shibboleth", 2) phonemically compact, and 3) phonetically diverse, but the selection itself was not well defined. Nevertheless, it is a very robust dataset with a time-aligned transcription and a usage guide to automatic speech recognition applications.

The CHiME articles \cite{christensen2010chime} \cite{barker2013pascal}, \cite{barker2018fifth} (and more), are also source of structured speech corpora creation, challenging researchers to better recognize speech within an everyday listening environment using multiple distant microphones. Since the focus of these works lies on nonoptimal recording conditions, detailed information on the noise background, noise level, recording style and speech material has been provided, as well as comprehensive postprocessing work.

A more recent work by \cite{chanchaochai2018globaltimit} attempts to extend the TIMIT functionality to other languages, by providing a method to create "TIMIT-like" datasets. These datasets are caracterized by having 1) Multiple (anonymously) identified speakers, 2) Wide range of phonetically representative inputs, 3) Wideband recordings with good acoustic quality, 4) Time-aligned lexical and phonemic transcripts and 5) Easily availability to anyone. The authors detail the speakers and sessions, the text corpus selection process, the recording procedures, as well as the transcription and alignment methods. At the moment, there have been five datasets created, with more planned or in progress.

As for crowdfunding speech corpora, one viable alternative to contribute speech is VoxForge \cite{voxforge}. Besides being a free speech corpus repository under GPL licence, VoxForge also incorporates an acoustic model archive for open source speech recognition engines. This corpus has over 132h, 39h, 20h, 57h of recorded English, French, Italian, and German \footnote{As of January 20th of 2021, per metric from \url{http://www.voxforge.org/en/Downloads}, \url{http://www.voxforge.org/fr/Downloads}, \url{http://www.voxforge.org/de/Downloads}, and \url{http://www.voxforge.org/de/Downloads}, respectively.}, as well a variety of acoustic models for CMU Sphinx, Julius and HTK. The VoxForge platform presents itself as an alternative to closed source speech recognition engines, since many corpora must be purchased under restrictive licenses. This contribution tool has, however, a very limited user interface and a not a well-defined recording validation process, which could invalidate the corpus robustness.

Common Voice \cite{ardila2019common} is a more recent platform for recording and listening to speech. It is a multilingual speech corpus, containing, as of 11th of December of 2020\footnote{Common Voice Corpus 6.1 accessible on  \url{https://commonvoice.mozilla.org/en/datasets}}, 1,686h of validated speech in English, and over 50h of validated Portuguese speech, in addition to other 27 languages. The main feature of this platform is the crowdsourced validation process, which all recordings must go through so that they are included in the validated corpus. All speech data is free and available under CC-0, the most permissive of licenses, and some recordings contain speaker demographics. One caveat though, is the lack of statistical analysis of the validated data, to ensure it is able to provide a quality dataset for speech recognition services. Nevertheless, the corpus was empirically tested through Mozilla’s DeepSpeech Speech-to-Text, achieving an average Character Error Rate improvement of 5.99 ± 5.48 for twelve target languages (German, French, Italian, Turkish, Catalan, Slovenian, Welsh, Irish, Breton, Tatar, Chuvash, and Kabyle), proving its effectiveness.

\section*{Sistematic Literature Review}
Finally, to identify the characteristics of a speech corpus, a systematic literature review was performed \cite{kitchenham2009systematic}.

Searches were done on two electronic databases: 1) Web of Science and 2) Scopus. The process for choosing relevant papers is defined below and can be applied to both of the electronic databases.

\section{Search in papers database}

The first step in the process is searching for papers in the specified database (1). To allow reproducibility, the search query is presented in table \ref{tab:search-terms}. These results are filtered down by Open Access criteria, publication data (2020~2023) and language (English) (2) - such filter will ensure the most recent accessible publications. Due to corpora being present at conferences, all article types were considered in this search. From this reduced set, results got filtered by title and keywords (3), and afterwards, by abstract (4).

\begin{table}[ht]
    \centering
    \caption{Search query used in the SLR}
    \begin{threeparttable}
      \begin{tabular}{|l|l|}
        \hline
        Digital Library & Search Terms \\ \hline
        Web of Science & TOPIC: ("speech corpus" OR "speech corpora")\tnote{1} \\ \hline
        Scopus & 
        \makecell[l]{TITLE-ABS-KEY ( "speech corpus"  OR  "speech corpora" ) AND \\
(  LIMIT-TO ( OA ,  "all" ) ) AND \\
( LIMIT-TO ( PUBYEAR ,  2023 ) OR \\
LIMIT-TO ( PUBYEAR ,  2022 ) OR \\
LIMIT-TO ( PUBYEAR ,  2021 ) OR \\
LIMIT-TO ( PUBYEAR ,  2020 ) OR \\
( LIMIT-TO ( LANGUAGE ,  "English" ) )\tnote{2}} \\ \hline
      \end{tabular}
      \begin{tablenotes}
        \footnotesize
        \item[1] Query link for Web Of Science Search: \url{https://www.webofscience.com/wos/woscc/summary/ae3cf854-30d2-4ea5-9b4e-ef7ecd11f7d5-557004b8/relevance/1}
        \item[2] Query link for Scopus Search: \url{https://www.scopus.com/results/results.uri?sort=plf-f&src=s&st1=%22speech+corpus%22+or+%22speech+corpora%22&nlo=&nlr=&nls=&sid=e9a2f20f7a443e09d21386133a8507e6&sot=b&sdt=cl&cluster=scofreetoread%2c%22all%22%2ct%2bscopubyr%2c%222023%22%2ct%2c%222022%22%2ct%2c%222021%22%2ct%2c%222020%22%2ct%2bscolang%2c%22English%22%2ct&sl=50&s=TITLE-ABS-KEY%28%22speech+corpus%22+or+%22speech+corpora%22%29&origin=resultslist&zone=leftSideBar&editSaveSearch=&txGid=791148437ed7352983d84d53a94d120}
      \end{tablenotes}
    \end{threeparttable}
    \caption*{Source: Author}
    \label{tab:search-terms}
\end{table}

\section{Inclusions and exclusions}

To filter relevant results, we define the criteria to include or exclude the articles based on each abstract read:

\subsection*{Inclusion Criteria}

\begin{itemize}
    \item Creates a speech corpus
    \item Define or discuss speech corpus creation
    \item Publication date from 2020 to 2023
    \item Published in English
\end{itemize}

\subsection*{Exclusion Criteria}

\begin{itemize}
    \item Full text not available in the electronic document
    \item Does not contain "speech corpus" or "speech corpora" strings in title, abstract, or keywords.
\end{itemize}

\section{Article Analysis}

After applying the proper filtering as defined in the previous section, the remaining articles can be fully read to find the results. The whole filtering process is summarized in \ref{tab:slr-filtering}.

\begin{table}[ht]
    \centering
    \caption{SLR - Filtering of results}
    \begin{tabular}{|c|c|c|c|}
        \hline 
        Step & Description & Web Of Science Results & Scopus Results \\ \hline
        1 & Initial search & 2,445 & 3,721 \\ \hline
        2 & Initial Filter & 119 & 215 \\ \hline
        3 & Title filtering & 25 \\ \hline
        4 & Abstract reading & BBB \\ \hline
    \end{tabular}
    \caption*{Source: Author - Executed October 12th 2022. Initial filter reduces set by filtering Open Access, publication date, and language.}
    \label{tab:slr-filtering}
\end{table}

\section{Findings}

To analytically organize our findings, a content-analysis approach was used. To choose the categories in which the content analysis is applied, we adapted the work from \cite{queiroz2019blockchain}, resulting in table \ref{tab:content-analysis}. As for the corpus categories, we sought a comparison work from  \cite{LeRouxVincent2014TRdatasets}, in which a comprehensive table was provided and adapted to fit our categorization needs.

\begin{table}[ht]
    \centering
    \caption{Categories for content analysis}
    \begin{tabular}{|p{4cm}|p{11cm}|}
        \hline Category & Explanation/Example \\ \hline
        Total number of papers published & Number of publications by year \\ \hline
        Application area & Speech Corpus, Learning English Pronunciation, Automatic Speech Recognition, Crowdsourcing \\ \hline
        Application context & Speech Corpus Creation, Speech Corpus Automated Analysis, Dialect Analysis \\ \hline
        Corpus Language & English (Dialect), Arabic, Multilingual, etc \\ \hline
    \end{tabular}
    \caption*{Source: Author}
    \label{tab:content-analysis}
\end{table}

\begin{table}[ht]
    \centering
    \caption{Categories for speech corpus construction}
    \begin{tabular}{|p{4cm}|p{11cm}|}
        \hline Category & Explanation/Example \\ \hline
        General attributes & scenario, total duration, sampling rate, number of distant or noisy microphones, demographics, transcription and time alignment and open access \\ \hline
        Speech attributes & duration of speech, speaking style, speakers in the room, speaker overlap\\ \hline
        Channel attributes & channel type, speaker location, speaker movements \\ \hline
        Noise attributes & stationary background noise, car noise, meeting noises, domestic noises, outdoor noises \\ \hline
        Available ground truth & reference speech signal, speaker location and orientation, paralinguistic attributes, noise events \\ \hline
    \end{tabular}
    \caption*{Source: Author}
    \label{tab:speech-analysis}
\end{table}

\subsection{Publication by country and year}

Table \ref{tab:country-analysis} reports the number of papers, published by country and year, resulting from the research protocol application.

\begin{table}[ht]
    \centering
    \caption{Countries for content analysis}
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline Country & 2005-2015 & 2016 & 2017 & 2018 & (\%) \\ \hline
        United States & - & 3 & 2 & - & 33\% \\ \hline 
        Japan & 3 & - & - & - & 20\% \\ \hline
        Emirates Arabs & - & - & 1 & 1 & 13\% \\ \hline
        India & - & - & 1 & - & 6.7\% \\ \hline
        Malasya & - & - & 1 & - & 6.7\% \\ \hline
        Sweden & - & - & 1 & - & 6.7\% \\ \hline
        China & - & 1 & - & - & 6.7\% \\ \hline
        Poland & 1 & - & - & - & 6.7\% \\ \hline
    \end{tabular}
    \caption*{Source: Author}
    \label{tab:country-analysis}
\end{table}

\subsection{Publication by type}

As for publication types, they have almost been equally divided: 46.7\% for articles and 53.3\% for proceedings papers.

\subsection{Speech Corpus studies' categorization}

In table \ref{tab:results-categorization}, each article is categorized according to table \ref{tab:content-analysis} definitions. The analysis is done afterwards in section \ref{sec:discussion}.

\begin{landscape}
\centering
\begin{longtable}{|p{2cm}|p{4.5cm}|p{10cm}|p{4.5cm}|}
    \caption{Findings organized by speech corpus categorization as per table \ref{tab:content-analysis}}
    \label{tab:results-categorization}\\
    \hline Authors & Application area & Context & Language \\ \hline
    \cite{almeman2018building} & Read Corpus & Multi-dialect Arabic corpora is scarce and not generated on mobile & Arabic \\ \hline
    \cite{dwivedi2017documenting} & Language Documentation & Revitalization of endangered languages through corpus creation & Kanauji of Kanpur \\ \hline
    \cite{bougrine2017altruistic} & Crowdsourcing & Crowdsourcing is a emerging and collaborative approach and can be effectively used to annotate linguistic resources & Arabic Algerian Dialects \\ \hline
    \cite{ng2017shefce} & Automatic syllable and phoneme detection & Pronunciation assessment studies in a bilingual context & Billingual (Cantonese, English) \\ \hline
    \cite{moore2017sheffield} & Read Speech & Goal oriented conversation & British English with a southern accent \\ \hline
    \cite{ramli2017first} & Storytelling Speech & Under-resourced language corpus creation for humanoid robot storyteller & Malay \\ \hline
    \cite{mansikkaniemi2017automatic} & Automatic speech alignment & Transcribed speech is a scarce and expensive resource & Finish \\ \hline
    \cite{goldman2016siwis} & Cross language speaker adaptation & Cross-lingual studies have no speech corpus from the same speakers & Bilingual and Trilingual from (English, French, German and Italian) \\ \hline
    \cite{liu2016sheffield} & Spontaneous Speech & Distant speech recognition with multi-channel speech corpus & English \\ \hline
    \cite{ruilan2016improving} & Read Corpus & Pronunciation characteristics in non-native English speakers & Dialectal English \\ \hline
    \cite{klessa2013paralingua} & Read Corpus & Paralinguistic features detection for forensics & Paralinguistic \\ \hline
    \cite{nagino2008building} & Corpus Enhancement & Low cost speech corpus creation with statistical multidimensional scaling method & Japanese \\ \hline
    \cite{zhang2008improved} & Phonetic words selection & Phonetically rich word selection from larger corpus & Chinese \\ \hline
    \cite{clopper2006nationwide} & Read Corpus & Large amount of speech by male and female from six dialect regions & Multiple-dialect English \\ \hline
\caption*{Source: Author}
\end{longtable}
\end{landscape}

\begin{landscape}
\centering
\begin{longtable}{|p{4cm}|p{5cm}|p{7cm}|p{3.5cm}|}
    \caption{Speech corpora characteristics defined in table \ref{tab:speech-analysis}}
    \label{tab:results-attributes}\\
    \hline Category & Characteristic & Work(s) & Quantity (out of 14)  \\ \hline
\multirow{7}{*}{General attributes} 
    & Scenario & 
    \cite{almeman2018building}, \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{bougrine2017altruistic}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis}, \cite{liu2016sheffield}, \cite{ruilan2016improving}, \cite{klessa2013paralingua}, \cite{nagino2008building},  \cite{clopper2006nationwide}, \cite{zhang2008improved} & 13
    \\ \cline{2-4} & Total duration &
    \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{bougrine2017altruistic}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis}, \cite{liu2016sheffield}, \cite{ruilan2016improving}, \cite{klessa2013paralingua}, \cite{nagino2008building}, \cite{clopper2006nationwide}, \cite{zhang2008improved} & 12
    \\ \cline{2-4} & Sampling Rate &
    \cite{almeman2018building}, \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{ng2017shefce}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis}, \cite{liu2016sheffield}, \cite{ruilan2016improving}, \cite{klessa2013paralingua}, \cite{clopper2006nationwide} & 11
    \\ \cline{2-4}& Distant or noisy microphones & 
    \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{liu2016sheffield} & 3
    \\ \cline{2-4} & Demographics &
    \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{ng2017shefce}, \cite{goldman2016siwis}, \cite{ruilan2016improving}, \cite{klessa2013paralingua}, \cite{clopper2006nationwide} & 7
    \\ \cline{2-4} & Transcription and time alignment & % manual?
    \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{bougrine2017altruistic}, \cite{ng2017shefce}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis}, \cite{liu2016sheffield}, \cite{ruilan2016improving}, \cite{klessa2013paralingua}, \cite{nagino2008building}, \cite{clopper2006nationwide} & 12
    \\ \cline{2-4} & Open access &
    \cite{almeman2018building}, \cite{moore2017sheffield}, \cite{liu2016sheffield} & 3
\\ \hline \multirow{3}{*}{Speech attributes}
    & Unique words & 
    \cite{bougrine2017altruistic}, \cite{bougrine2017altruistic}, \cite{ng2017shefce}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis}, \cite{liu2016sheffield}, \cite{ruilan2016improving}, \cite{klessa2013paralingua}, \cite{nagino2008building}, \cite{clopper2006nationwide} & 11
    \\ \cline{2-4} & Speaking style &
    \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{ng2017shefce}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis}, \cite{nagino2008building}, \cite{clopper2006nationwide} & 8
    \\ \cline{2-4} & Number of speakers & 
    \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{bougrine2017altruistic}, \cite{ng2017shefce}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis},, \cite{ruilan2016improving} \cite{liu2016sheffield}, \cite{klessa2013paralingua}, \cite{nagino2008building}, \cite{clopper2006nationwide} & 14
\\ \hline \multirow{3}{*}{Channel attributes}
    & Channel type & 
    \cite{dwivedi2017documenting}, \cite{bougrine2017altruistic}, \cite{ng2017shefce}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{goldman2016siwis}, \cite{liu2016sheffield}, \cite{ruilan2016improving}, \cite{nagino2008building}, \cite{clopper2006nationwide} & 10
    \\ \cline{2-4} & Speaker location & 
    \cite{dwivedi2017documenting}, \cite{ng2017shefce}, \cite{liu2016sheffield} & 3
    \\ \cline{2-4} & Speaker movements & 
    \cite{dwivedi2017documenting}, \cite{moore2017sheffield}, \cite{liu2016sheffield} & 3
\\ \hline \multirow{1}{*}{Noise attributes}
    & Noise type & N/A &
    0
\\ \hline \multirow{4}{*}{Available ground truth} 
    & Reference speech signal & 
    \cite{ng2017shefce}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{liu2016sheffield} & 4
    \\ \cline{2-4} & Speaker location and orientation &
    \cite{bougrine2017altruistic}, \cite{moore2017sheffield}, \cite{ramli2017first}, \cite{liu2016sheffield} & 4
    \\ \cline{2-4} & Paralinguistic attributes &
    \cite{klessa2013paralingua} & 1 \\ \cline{2-4} & Noise events & 
    \cite{ramli2017first} & 1 \\ \hline
\caption*{Source: Author}
\end{longtable}
\end{landscape}

\section{Discussion}
\label{sec:discussion}

\subsection{Publications by country and year}

A simple analysis on table \ref{tab:country-analysis} infers that the research on speech corpus creation was stable until 2018, year in which its last article was published. This can be explained by the limited number of "Open Access" articles found and the small number of databases searched (Web Of Science only). A more permissive literature review should enable to better understand the conditions on which non-open articles are being released, as well as enhance coverage of the state-of-the-art in this field.

The table also categorizes the countries research quota. More developed countries such as United States and Japan have created more corpora over the years.

\subsection{Publications by type}

In the search executed, the remaining articles were almost equally separated by type. A great number of conference proceedings may indicate that the corpus creation process is not properly defined, as works vary in content and structure. Again, the main limitation of this work is the only database searched, therefore skewing analysis.

\subsection{Speech corpus categorization}

Table \ref{tab:content-analysis} contains the content-analysis for the works in the systematic literature review. Two of the columns - Application Area (1), and Language (2) - are be discussed below:

\subsubsection{Application Area}

Most of the corpora found in the articles were a Read Speech Corpus (\cite{almeman2018building}, \cite{ruilan2016improving}, \cite{klessa2013paralingua}, \cite{clopper2006nationwide}), revealing the lack of structured language documentation in the current research. This can be explained by the type of its content: a scripted content, with less bias from the speakers when compared to spontaneous corpora. Three of these studies (\cite{ng2017shefce}, \cite{mansikkaniemi2017automatic} and \cite{nagino2008building}) worked on automating corpus creation by automatically aligning words, detecting syllables and phonemes, and even enhancing corpora, as most recording and alignment work is currently done manually.

\subsubsection{Languages}

There is a significant number of dialect and multilingual corpora research in the analyzed works. These variations of the same language - in different regions, or by different pronunciation by non-native speakers -, suggest that speech technology could become more personalized as computers understand less traditional utterances of the same language.

\subsection{Works by speech corpus characteristics}

Our findings condensed in table \ref{tab:results-categorization} illustrate the
current speech corpus creation characteristics used in the literature, each discussed below:

\subsubsection{Scenario}

Almost all corpora specified the scenario in which the recordings were executed. A meeting room (\cite{liu2016sheffield}, \cite{moore2017sheffield}); a anechoic booth (\cite{goldman2016siwis}); a quiet room inside a laboratory (\cite{ramli2017first}), etc. Although, each corpus is not limited to one scenario. For instance, \cite{almeman2018building} recorded in four different scenarios: inside the home, in a moving car, in a public place, and in a quiet place. Such characteristic is critical to corpus creation.

\subsubsection{Total duration}

12 out of the 14 studies analyzed described the total duration of the recordings. This illustrates the importance of being descriptive in the corpus.

\subsubsection{Sampling Rate}

The sampling rate is major to the corpus creation. It is cited in 11 out of the 14 works read. The reason it has so much importance lies in the corpus main usage: automatic speech recognition software. Knowing the frequency at which the recordings are undertaken, the computer is able to better recognize subtleties in a more sampled audio, as well as simplify processing in a lower frequency sample rate.

\subsubsection{Noisy microphones}

Non-optimal recording conditions are normal. For instance, speaking on the phone in a public space generates a very high noisy background \cite{moore2017sheffield}). Moreover, speaking far from the microphone is also a common occurrence. The presence of works in this category emphasizes the need of noisy corpora to ensure automatic speech recognition software takes these factors into account.

\subsubsection{Demographics}

When recording accent (\cite{moore2017sheffield}), dialect (\cite{almeman2018building}) and pronunciation (\cite{ng2017shefce}), the definition of speaker demographics supports the understanding of the variations between the same language through research.

\subsubsection{Transcription and time alignment}

In the context of automatic speech recognition, a speech corpus containing  transcription and time alignment (additional to the recordings) enable computers and speech recognition specialists a more faithful analysis. Its importance can be verified in 85\% of the works evaluated.

%\subsubsection{Open access}

%Most corpora are closed to the public viewer. 

%\subsubsection{Unique words}
%\subsubsection{Speaking style}
\subsubsection{Number of speakers}

As well as the total duration, the number of speakers is a major characteristic of the corpus. More speakers lead to more representativeness, but also affect the corpus recording time. It is an important parameter and every paper analyzed describes it.
